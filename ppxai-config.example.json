{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "version": "1.0",
  "default_provider": "perplexity",
  "providers": {
    "perplexity": {
      "name": "Perplexity AI",
      "base_url": "https://api.perplexity.ai",
      "api_key_env": "PERPLEXITY_API_KEY",
      "default_model": "sonar-pro",
      "coding_model": "sonar-pro",
      "models": {
        "sonar": {
          "name": "Sonar",
          "description": "Lightweight search model with real-time grounding"
        },
        "sonar-pro": {
          "name": "Sonar Pro",
          "description": "Advanced search model for complex queries"
        },
        "sonar-reasoning": {
          "name": "Sonar Reasoning",
          "description": "Fast reasoning model for problem-solving with search"
        },
        "sonar-reasoning-pro": {
          "name": "Sonar Reasoning Pro",
          "description": "Precision reasoning with Chain of Thought capabilities"
        },
        "sonar-deep-research": {
          "name": "Sonar Deep Research",
          "description": "Exhaustive research with comprehensive reports"
        }
      },
      "pricing": {
        "sonar": {"input": 0.20, "output": 0.20},
        "sonar-pro": {"input": 3.00, "output": 15.00},
        "sonar-reasoning": {"input": 1.00, "output": 5.00},
        "sonar-reasoning-pro": {"input": 5.00, "output": 15.00},
        "sonar-deep-research": {"input": 5.00, "output": 15.00}
      },
      "capabilities": {
        "web_search": true,
        "web_fetch": true,
        "weather": true,
        "realtime_info": true
      }
    },
    "openai": {
      "name": "OpenAI ChatGPT",
      "base_url": "https://api.openai.com/v1",
      "api_key_env": "OPENAI_API_KEY",
      "default_model": "gpt-4o",
      "coding_model": "gpt-4o",
      "models": {
        "gpt-4o": {
          "name": "GPT-4o",
          "description": "Latest flagship model with vision"
        },
        "gpt-4o-mini": {
          "name": "GPT-4o Mini",
          "description": "Fast and affordable for simple tasks"
        },
        "gpt-4-turbo": {
          "name": "GPT-4 Turbo",
          "description": "Previous generation with 128K context"
        },
        "o1": {
          "name": "o1",
          "description": "Advanced reasoning model"
        },
        "o1-mini": {
          "name": "o1 Mini",
          "description": "Fast reasoning model"
        }
      },
      "pricing": {
        "gpt-4o": {"input": 2.50, "output": 10.00},
        "gpt-4o-mini": {"input": 0.15, "output": 0.60},
        "gpt-4-turbo": {"input": 10.00, "output": 30.00},
        "o1": {"input": 15.00, "output": 60.00},
        "o1-mini": {"input": 3.00, "output": 12.00}
      },
      "capabilities": {
        "web_search": false,
        "web_fetch": false,
        "weather": false,
        "realtime_info": false
      }
    },
    "openrouter": {
      "name": "OpenRouter",
      "base_url": "https://openrouter.ai/api/v1",
      "api_key_env": "OPENROUTER_API_KEY",
      "default_model": "anthropic/claude-sonnet-4",
      "coding_model": "anthropic/claude-sonnet-4",
      "models": {
        "anthropic/claude-sonnet-4": {
          "name": "Claude Sonnet 4",
          "description": "Anthropic's balanced model for most tasks"
        },
        "anthropic/claude-opus-4": {
          "name": "Claude Opus 4",
          "description": "Anthropic's most capable model"
        },
        "anthropic/claude-haiku": {
          "name": "Claude Haiku",
          "description": "Fast and affordable Claude model"
        },
        "google/gemini-2.0-flash-001": {
          "name": "Gemini 2.0 Flash",
          "description": "Google's fast multimodal model"
        },
        "meta-llama/llama-3.1-405b-instruct": {
          "name": "Llama 3.1 405B",
          "description": "Meta's largest open model"
        }
      },
      "pricing": {
        "anthropic/claude-sonnet-4": {"input": 3.00, "output": 15.00},
        "anthropic/claude-opus-4": {"input": 15.00, "output": 75.00},
        "anthropic/claude-haiku": {"input": 0.25, "output": 1.25},
        "google/gemini-2.0-flash-001": {"input": 0.10, "output": 0.40},
        "meta-llama/llama-3.1-405b-instruct": {"input": 3.00, "output": 3.00}
      },
      "capabilities": {
        "web_search": false,
        "web_fetch": false,
        "weather": false,
        "realtime_info": false
      }
    },
    "local-vllm": {
      "name": "Local vLLM",
      "base_url": "http://localhost:8000/v1",
      "api_key_env": "LOCAL_API_KEY",
      "default_model": "meta-llama/Llama-3-70b",
      "coding_model": "meta-llama/Llama-3-70b",
      "models": {
        "meta-llama/Llama-3-70b": {
          "name": "Llama 3 70B",
          "description": "Self-hosted Llama 3 70B model"
        }
      },
      "pricing": {
        "meta-llama/Llama-3-70b": {"input": 0.0, "output": 0.0}
      },
      "capabilities": {
        "web_search": false,
        "web_fetch": false,
        "weather": false,
        "realtime_info": false
      }
    },
    "ollama": {
      "name": "Ollama Local",
      "base_url": "http://localhost:11434/v1",
      "api_key_env": "OLLAMA_API_KEY",
      "default_model": "llama3.2",
      "coding_model": "codellama",
      "models": {
        "llama3.2": {
          "name": "Llama 3.2",
          "description": "Latest Llama model via Ollama"
        },
        "codellama": {
          "name": "Code Llama",
          "description": "Specialized coding model"
        },
        "mistral": {
          "name": "Mistral 7B",
          "description": "Fast and efficient model"
        }
      },
      "pricing": {
        "llama3.2": {"input": 0.0, "output": 0.0},
        "codellama": {"input": 0.0, "output": 0.0},
        "mistral": {"input": 0.0, "output": 0.0}
      },
      "capabilities": {
        "web_search": false,
        "web_fetch": false,
        "weather": false,
        "realtime_info": false
      }
    }
  }
}
